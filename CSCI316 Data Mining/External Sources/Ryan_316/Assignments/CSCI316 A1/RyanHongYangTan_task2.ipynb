{"cells":[{"cell_type":"markdown","source":["**Individual Assignment 1 Task 2**\n","\n","Name: Ryan Hong Yang Tan\n","\n","UOW ID: 8560341"],"metadata":{"id":"KUXrDi57PV7W"}},{"cell_type":"markdown","source":["Reading the csv file into a dataframe and checking for its length"],"metadata":{"id":"3djyHk1rFUpb"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3169,"status":"ok","timestamp":1738742829854,"user":{"displayName":"Ryan","userId":"17568250420192538448"},"user_tz":-480},"id":"5l_IyFDMONwu","outputId":"aee388ff-2fe6-4e98-cd02-d33d8b3f8c95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","61069 \n","\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import math\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","# Reading the csv file\n","data = pd.read_csv('/content/drive/My Drive/secondary_data.csv', sep=';')\n","# Checking if the data size is correct\n","print(len(data), '\\n')"]},{"cell_type":"markdown","source":["**Pre-processing:**\n","Checking for null values, categorical values are cleaned by filling with the mode while continuous values are cleaned by filling with the mean"],"metadata":{"id":"ig-ExV13FdbW"}},{"cell_type":"code","source":["# Checking for null values\n","print('Null values present before pre processing:')\n","print(data.isnull().sum())\n","\n","# Pre-processing\n","def preprocessing(dataName):\n","  for col in data.columns:\n","    # Categorical data are cleaned using mode\n","    if dataName[col].dtype == 'object':\n","      # Fills null data with the mode by selecting the mode value of the column\n","      dataName[col] = dataName[col].fillna(dataName[col].mode()[0])\n","    # Continuous data are cleaned using mean\n","    else:\n","      # Fills null data with the mean value\n","      dataName[col] = dataName[col].fillna(dataName[col].mean())\n","  return dataName\n","\n","# Running the pre processing function\n","data = preprocessing(data)\n","\n","# Checking for null values\n","print('\\nNull values present after pre processing:')\n","print(data.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"We2vBgwnF9z3","executionInfo":{"status":"ok","timestamp":1738742830260,"user_tz":-480,"elapsed":409,"user":{"displayName":"Ryan","userId":"17568250420192538448"}},"outputId":"7a7493ee-8759-4715-b384-535c87c4f75e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Null values present before pre processing:\n","class                       0\n","cap-diameter                0\n","cap-shape                   0\n","cap-surface             14120\n","cap-color                   0\n","does-bruise-or-bleed        0\n","gill-attachment          9884\n","gill-spacing            25063\n","gill-color                  0\n","stem-height                 0\n","stem-width                  0\n","stem-root               51538\n","stem-surface            38124\n","stem-color                  0\n","veil-type               57892\n","veil-color              53656\n","has-ring                    0\n","ring-type                2471\n","spore-print-color       54715\n","habitat                     0\n","season                      0\n","dtype: int64\n","\n","Null values present after pre processing:\n","class                   0\n","cap-diameter            0\n","cap-shape               0\n","cap-surface             0\n","cap-color               0\n","does-bruise-or-bleed    0\n","gill-attachment         0\n","gill-spacing            0\n","gill-color              0\n","stem-height             0\n","stem-width              0\n","stem-root               0\n","stem-surface            0\n","stem-color              0\n","veil-type               0\n","veil-color              0\n","has-ring                0\n","ring-type               0\n","spore-print-color       0\n","habitat                 0\n","season                  0\n","dtype: int64\n"]}]},{"cell_type":"markdown","source":["**Selecting features to be used**, features selected being cap-diameter, stem-height, cap-shape, cap-color, does-bruise-or-bleed\n","\n","Class column has to be included as it represents whether its poisonous or edible"],"metadata":{"id":"y5EnDB_zGZNl"}},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1738742830260,"user":{"displayName":"Ryan","userId":"17568250420192538448"},"user_tz":-480},"id":"2Bsi_4aluhlk"},"outputs":[],"source":["features = ['cap-diameter', 'stem-height', 'cap-shape', 'cap-color', 'does-bruise-or-bleed']\n","classData = 'class'\n","data = data[features + [classData]]"]},{"cell_type":"markdown","source":["**Binning and Encoding**"],"metadata":{"id":"O3wa9TFBG8nV"}},{"cell_type":"code","source":["# Binning function\n","def binning(col, binCount):\n","  return pd.qcut(col, binCount, labels = [0,1,2])\n","\n","# Performing binning on continuous features\n","data['stem-height'] = binning(data['stem-height'], 3)\n","data['cap-diameter'] = binning(data['cap-diameter'], 3)\n","\n","# Encoding categorical features\n","for cols in data.select_dtypes(include='object').columns:\n","  data[cols] = data[cols].astype('category').cat.codes\n","\n","# Checking if all values are binned/encoded\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0IXMiWD7G_HB","executionInfo":{"status":"ok","timestamp":1738742830260,"user_tz":-480,"elapsed":9,"user":{"displayName":"Ryan","userId":"17568250420192538448"}},"outputId":"e02e3f23-3bc1-475e-8efb-fc69e7c3d632"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["      cap-diameter stem-height  cap-shape  cap-color  does-bruise-or-bleed  \\\n","0                2           2          6          6                     0   \n","1                2           2          6          6                     0   \n","2                2           2          6          6                     0   \n","3                2           2          2          1                     0   \n","4                2           2          6          6                     0   \n","...            ...         ...        ...        ...                   ...   \n","61064            0           0          5         11                     0   \n","61065            0           0          2         11                     0   \n","61066            0           0          5         11                     0   \n","61067            0           0          2         11                     0   \n","61068            0           0          5         11                     0   \n","\n","       class  \n","0          1  \n","1          1  \n","2          1  \n","3          1  \n","4          1  \n","...      ...  \n","61064      1  \n","61065      1  \n","61066      1  \n","61067      1  \n","61068      1  \n","\n","[61069 rows x 6 columns]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-bf8b6b2ae800>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['stem-height'] = binning(data['stem-height'], 3)\n","<ipython-input-6-bf8b6b2ae800>:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['cap-diameter'] = binning(data['cap-diameter'], 3)\n","<ipython-input-6-bf8b6b2ae800>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data[cols] = data[cols].astype('category').cat.codes\n","<ipython-input-6-bf8b6b2ae800>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data[cols] = data[cols].astype('category').cat.codes\n","<ipython-input-6-bf8b6b2ae800>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data[cols] = data[cols].astype('category').cat.codes\n","<ipython-input-6-bf8b6b2ae800>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data[cols] = data[cols].astype('category').cat.codes\n"]}]},{"cell_type":"markdown","source":["**Splitting** dataset into training and post prune datasets"],"metadata":{"id":"LuUObg7MHOZr"}},{"cell_type":"code","source":["# Splitting function\n","def train_test_split(data, test_size):\n","  if isinstance(test_size, float):\n","    test_size = round(test_size * len(data))\n","\n","  indices = data.index.tolist()\n","  test_indices = random.sample(population=indices, k=test_size)\n","\n","  test_data = data.loc[test_indices]\n","  train_data = data.drop(test_indices)\n","\n","  return train_data, test_data\n","\n","# Splitting the data into training(2/3) and post-pruning(1/3)\n","random.seed(42)\n","train_data, post_prune_data = train_test_split(data, 0.33)\n","\n","# Checking size of each data set, they should add up to the full dataset size (61069 in this case)\n","print('Training data size:', len(train_data))\n","print('Post-prunning data size:', len(post_prune_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIjE72hJHUFc","executionInfo":{"status":"ok","timestamp":1738742830260,"user_tz":-480,"elapsed":6,"user":{"displayName":"Ryan","userId":"17568250420192538448"}},"outputId":"a9994afe-4119-49af-a7ac-491b658da632"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data size: 40916\n","Post-prunning data size: 20153\n"]}]},{"cell_type":"markdown","source":["**Calculate entropy functions**"],"metadata":{"id":"NyYbkPVoHZqO"}},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1738742830260,"user":{"displayName":"Ryan","userId":"17568250420192538448"},"user_tz":-480},"id":"TfCO9I4vuUb2"},"outputs":[],"source":["def calculate_entropy(data):\n","    label_col = data[:, -1]\n","    _, counts = np.unique(label_col, return_counts=True)\n","    prob = counts / counts.sum()\n","    entropy = sum(prob * -np.log2(prob))\n","    return entropy\n","\n","def calculate_child_entropy(left, right):\n","    total = len(left) + len(right)\n","    return ((len(left) / total) * calculate_entropy(left)) + ((len(right) / total) * calculate_entropy(right))"]},{"cell_type":"markdown","source":["**Get possible split function**"],"metadata":{"id":"HJ2phVcXHdZy"}},{"cell_type":"code","source":["def get_possible_splits(data):\n","    possible_splits = {}\n","    n_rows, n_cols = data.shape\n","    for col in range(n_cols - 1):\n","        possible_splits[col] = []\n","        values = data[:, col]\n","        unique_values = np.unique(values)\n","        possible_splits[col] = unique_values\n","    return possible_splits"],"metadata":{"id":"Lxo8Dn-kHfe4","executionInfo":{"status":"ok","timestamp":1738742830260,"user_tz":-480,"elapsed":4,"user":{"displayName":"Ryan","userId":"17568250420192538448"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["**Split data function**"],"metadata":{"id":"P7C3SQJ3Hp7o"}},{"cell_type":"code","source":["def split_data(data, split_col, split_val):\n","    split_col_val = data[:, split_col]\n","    left = data[split_col_val == split_val]\n","    right = data[split_col_val != split_val]\n","    return left, right"],"metadata":{"id":"LEyEpCbGHrK-","executionInfo":{"status":"ok","timestamp":1738742830260,"user_tz":-480,"elapsed":4,"user":{"displayName":"Ryan","userId":"17568250420192538448"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["**Determine Best split function**"],"metadata":{"id":"HQfbsiDAHwgN"}},{"cell_type":"code","source":["def determine_best_split(data, possible_splits):\n","    parent_entropy = calculate_entropy(data)\n","    best_entropy = parent_entropy\n","    best_split_col = None\n","    best_split_val = None\n","\n","    for col_index in possible_splits:\n","        for value in possible_splits[col_index]:\n","            left, right = split_data(data, col_index, value)\n","            if len(left) == 0 or len(right) == 0:\n","                continue\n","            child_entropy = calculate_child_entropy(left, right)\n","            if child_entropy < best_entropy:\n","                best_split_col = col_index\n","                best_split_val = value\n","                best_entropy = child_entropy\n","\n","    return best_split_col, best_split_val"],"metadata":{"id":"KFMw3KeUH2gv","executionInfo":{"status":"ok","timestamp":1738742830260,"user_tz":-480,"elapsed":4,"user":{"displayName":"Ryan","userId":"17568250420192538448"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["**Function to check if we have reached a leaf node**"],"metadata":{"id":"wGLWlGL2H5qv"}},{"cell_type":"code","source":["def check_leaf(data):\n","    label_col = data[:, -1]\n","    classes = np.unique(label_col)\n","    return len(classes) == 1"],"metadata":{"id":"tex5IbsxH9G2","executionInfo":{"status":"ok","timestamp":1738742830261,"user_tz":-480,"elapsed":4,"user":{"displayName":"Ryan","userId":"17568250420192538448"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["**Classify data functions**"],"metadata":{"id":"5hKOBJfnIBwA"}},{"cell_type":"code","source":["def classify_data(data):\n","    label_col = data[:, -1]\n","    classes, counts = np.unique(label_col, return_counts=True)\n","    index = counts.argmax()\n","    classification = classes[index]\n","    return classification\n","\n","def classify_one(test_row, tree):\n","    question = list(tree.keys())[0]\n","    feature_name, _, value = question.split(\" \")\n","    if str(test_row[feature_name]) == value:\n","        answer = tree[question][0]\n","    else:\n","        answer = tree[question][1]\n","\n","    if not isinstance(answer, dict):\n","        return answer\n","    else:\n","        return classify_one(test_row, answer)"],"metadata":{"id":"anTb6efAIHA0","executionInfo":{"status":"ok","timestamp":1738742830631,"user_tz":-480,"elapsed":374,"user":{"displayName":"Ryan","userId":"17568250420192538448"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["**Function to build the decision tree**"],"metadata":{"id":"-0Wr9KmTIM_D"}},{"cell_type":"code","source":["def decision_tree_classifier(data, max_depth, min_samples, counter=0):\n","    global COL_HEADERS\n","    if counter == 0:\n","        COL_HEADERS = data.columns\n","        data = data.values\n","\n","    if check_leaf(data) or (len(data) < min_samples) or (counter == max_depth):\n","        classification = classify_data(data)\n","        return classification\n","\n","    else:\n","        counter += 1\n","        possible_splits = get_possible_splits(data)\n","        split_col, split_val = determine_best_split(data, possible_splits)\n","\n","        if split_col is None:\n","            return classify_data(data)\n","\n","        left, right = split_data(data, split_col, split_val)\n","\n","        feature_name = COL_HEADERS[split_col]\n","        question = f\"{feature_name} = {split_val}\"\n","\n","        sub_tree = {question: []}\n","\n","        yes_answer = decision_tree_classifier(left, max_depth, min_samples, counter)\n","        no_answer = decision_tree_classifier(right, max_depth, min_samples, counter)\n","\n","        if yes_answer == no_answer:\n","            sub_tree = yes_answer\n","        else:\n","            sub_tree[question].append(yes_answer)\n","            sub_tree[question].append(no_answer)\n","\n","        return sub_tree"],"metadata":{"id":"9XQKf9yYIP6C","executionInfo":{"status":"ok","timestamp":1738742830631,"user_tz":-480,"elapsed":2,"user":{"displayName":"Ryan","userId":"17568250420192538448"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["**Function to predict data with tree built**"],"metadata":{"id":"CS8MLstGHyma"}},{"cell_type":"code","source":["def predict(test_data, tree):\n","    output = []\n","    for _, row in test_data.iterrows():\n","        output.append(classify_one(row, tree))\n","    return output"],"metadata":{"id":"s_ltB_o9IWWI","executionInfo":{"status":"ok","timestamp":1738742830632,"user_tz":-480,"elapsed":3,"user":{"displayName":"Ryan","userId":"17568250420192538448"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["**Calculate accuracy function**"],"metadata":{"id":"DlvwMKSLIXEf"}},{"cell_type":"code","source":["def calculate_accuracy(test_data, tree):\n","    correct = 0\n","    for _, row in test_data.iterrows():\n","        true_label = row['class']\n","        pred_label = classify_one(row, tree)\n","        correct += (pred_label == true_label)\n","    return correct / len(test_data)"],"metadata":{"id":"qiQgxxSnIYrz","executionInfo":{"status":"ok","timestamp":1738742830632,"user_tz":-480,"elapsed":3,"user":{"displayName":"Ryan","userId":"17568250420192538448"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o9oQxtLDg4RR"},"source":["**Testing out the model**\n","\n","\n","1.   Building the tree\n","2.   Testing the accuracy\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1537,"status":"ok","timestamp":1738742832166,"user":{"displayName":"Ryan","userId":"17568250420192538448"},"user_tz":-480},"id":"DGtn7FXLg2nh","outputId":"c8b5d8f8-03ba-4df9-cac9-5cb7b9548a1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.6244727832084553\n"]}],"source":["decision_tree = decision_tree_classifier(train_data, max_depth=3, min_samples=2)\n","# output = predict(post_prune_data, decision_tree)\n","accuracy = calculate_accuracy(post_prune_data, decision_tree)\n","print(accuracy)"]},{"cell_type":"markdown","metadata":{"id":"USGqGHkFiOPY"},"source":["**Tuning depth of tree by testing it with a range of max depth**"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-bOiiH-3gcPr","executionInfo":{"status":"ok","timestamp":1738742879176,"user_tz":-480,"elapsed":47012,"user":{"displayName":"Ryan","userId":"17568250420192538448"}},"outputId":"e45ba81f-7255-421e-8bba-e02a4b703f0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Depth 1: 0.5690964124447973\n","Depth 2: 0.5973800426735474\n","Depth 3: 0.6244727832084553\n","Depth 4: 0.6450652508311417\n","Depth 5: 0.6479432342579269\n","Depth 6: 0.666153922492929\n","Depth 7: 0.6781124398352603\n","Depth 8: 0.6907656428323327\n","Depth 9: 0.6948345159529599\n","Depth 10: 0.7020790949238327\n","Depth 11: 0.7172629385203195\n","Depth 12: 0.7274847417257977\n","Depth 13: 0.7419738996675433\n","Depth 14: 0.7539820374137846\n","Depth 15: 0.7638068773879819\n","Depth 16: 0.7724904480722473\n","Depth 17: 0.7770059048280653\n","Depth 18: 0.7775021088671662\n","Depth 19: 0.7787426189649184\n","Depth 20: 0.783655038952017\n","Depth 21: 0.7848459286458592\n","Depth 22: 0.783655038952017\n","Depth 23: 0.783655038952017\n","Depth 24: 0.783655038952017\n","Highest accuracy: 0.7848459286458592 at depth 21\n"]}],"source":["# List of values to try for max_depth:\n","max_depth_range = list(range(1, 25))\n","highest_accuracy_depth = 0\n","highest_accuracy_for_depth = 0\n","\n","\n","for depth in max_depth_range:\n","  tree = decision_tree_classifier(train_data, max_depth = depth, min_samples = 2)\n","  score = calculate_accuracy(post_prune_data, tree)\n","  print(f'Depth {depth}: {score}')\n","  if score > highest_accuracy_for_depth:\n","    highest_accuracy_for_depth = score\n","    highest_accuracy_depth = depth\n","\n","print(f'Highest accuracy: {highest_accuracy_for_depth} at depth {highest_accuracy_depth}')"]},{"cell_type":"markdown","metadata":{"id":"CziMP7Gci4qP"},"source":["Results show that the accuracy increases all the way and peaks at depth 21 before decreasing"]},{"cell_type":"markdown","metadata":{"id":"8MH4yrjni67f"},"source":["**Tuning min sample of tree by testing it with a range of min sample**\n","\n","As accuracy peaked at max_depth = 21, it is decided for that to be the max_depth"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":123382,"status":"ok","timestamp":1738743144863,"user":{"displayName":"Ryan","userId":"17568250420192538448"},"user_tz":-480},"id":"VcUf8t2Ai2bI","outputId":"34b9c7c0-1502-41de-aa38-660646656032"},"outputs":[{"output_type":"stream","name":"stdout","text":["Min sample 1: 0.7848459286458592\n","Min sample 2: 0.7848459286458592\n","Min sample 3: 0.7848459286458592\n","Min sample 4: 0.7848459286458592\n","Min sample 5: 0.7848459286458592\n","Min sample 6: 0.7848459286458592\n","Min sample 7: 0.7846474470302188\n","Min sample 8: 0.7846474470302188\n","Min sample 9: 0.7846474470302188\n","Min sample 10: 0.7846474470302188\n","Min sample 11: 0.7846474470302188\n","Min sample 12: 0.7846474470302188\n","Min sample 13: 0.7845482062223986\n","Min sample 14: 0.7844985858184885\n","Min sample 15: 0.7844985858184885\n","Min sample 16: 0.784200863395028\n","Min sample 17: 0.784200863395028\n","Min sample 18: 0.784200863395028\n","Min sample 19: 0.784200863395028\n","Min sample 20: 0.7841016225872078\n","Min sample 21: 0.7841016225872078\n","Min sample 22: 0.7841016225872078\n","Min sample 23: 0.7841016225872078\n","Min sample 24: 0.7839527613754776\n","Min sample 25: 0.7839527613754776\n","Min sample 26: 0.7839527613754776\n","Min sample 27: 0.7839527613754776\n","Min sample 28: 0.7839527613754776\n","Min sample 29: 0.7839527613754776\n","Min sample 30: 0.7839527613754776\n","Min sample 31: 0.7839527613754776\n","Min sample 32: 0.7839527613754776\n","Min sample 33: 0.7839527613754776\n","Min sample 34: 0.7839527613754776\n","Min sample 35: 0.7839527613754776\n","Min sample 36: 0.7839527613754776\n","Min sample 37: 0.7841016225872078\n","Min sample 38: 0.7841016225872078\n","Min sample 39: 0.7840520021832977\n","Min sample 40: 0.7840520021832977\n","Min sample 41: 0.7840520021832977\n","Min sample 42: 0.7840520021832977\n","Min sample 43: 0.7840520021832977\n","Min sample 44: 0.7840520021832977\n","Min sample 45: 0.7840520021832977\n","Min sample 46: 0.7840520021832977\n","Min sample 47: 0.7841512429911179\n","Min sample 48: 0.7841512429911179\n","Min sample 49: 0.7839031409715675\n","Highest accuracy: 0.7848459286458592 at min_sample 1\n"]}],"source":["# # List of values to try for min_size:\n","min_size_range = list(range(1, 50))\n","highest_accuracy_min_size = 0\n","highest_accuracy_for_min_size = 0\n","\n","for size in min_size_range:\n","    tree = decision_tree_classifier(train_data, max_depth = 21, min_samples = size)\n","    score = calculate_accuracy(post_prune_data, tree)\n","    print(f'Min sample {size}: {score}')\n","    if score > highest_accuracy_for_min_size:\n","        highest_accuracy_for_min_size = score\n","        highest_accuracy_min_size = size\n","\n","print(f'Highest accuracy: {highest_accuracy_for_min_size} at min_sample {highest_accuracy_min_size}')"]},{"cell_type":"markdown","metadata":{"id":"csGuPIG-jV4f"},"source":["Results shown to be have started at its peak at min_sample 1, and remained constant till min_sample 6 before decreasing, however, in order to ensure that ample amount of data is used I have decided to set the min_sample at 5"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2487,"status":"ok","timestamp":1738743352077,"user":{"displayName":"Ryan","userId":"17568250420192538448"},"user_tz":-480},"id":"XnU_OpSIj3og","colab":{"base_uri":"https://localhost:8080/"},"outputId":"19411992-1430-4019-89eb-824653ae1ec9"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7848459286458592\n"]}],"source":["final_decision_tree = decision_tree_classifier(train_data, max_depth=21, min_samples=5)\n","final_accuracy = calculate_accuracy(post_prune_data, final_decision_tree)\n","print(final_accuracy)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyODiL/6IJS6gUMK2ulP94kL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
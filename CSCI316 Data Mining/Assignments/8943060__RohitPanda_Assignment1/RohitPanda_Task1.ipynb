{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Individual Assignment 1 Task 1\n",
        "# Name: Rohit Panda\n",
        "# UOW ID: 8943060"
      ],
      "metadata": {
        "id": "sA5PUmPV89kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before Running the code, ensure you have the kaggle.json file to upload into the Colab.\n",
        "\n",
        "Download the kaggle.json from this link:\n",
        "[Download Now](https://drive.google.com/file/d/15J5mknfkekOMMzW0bw6tjVwEmJj-e_C_/view?usp=sharing)"
      ],
      "metadata": {
        "id": "3JFtZV9celr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files  # if using Colab\n",
        "files.upload()  # upload kaggle.json\n",
        "\n",
        "# Move to the correct path\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ezC3StkM_l9W",
        "outputId": "540bacce-1b81-4932-ff94-330ecb01797d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7a1d3b81-427f-4128-b097-1e6320208a0f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7a1d3b81-427f-4128-b097-1e6320208a0f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhSY-i8b8bKD"
      },
      "outputs": [],
      "source": [
        "# Step 0: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set up Kaggle API credentials (Ensure kaggle.json is placed in ~/.kaggle or current directory)\n",
        "# If not done already, download your API token from Kaggle Account > API > Create New Token\n",
        "\n",
        "# Optional: Automatically set Kaggle API key location if in current directory\n",
        "if not os.path.exists(os.path.expanduser(\"~/.kaggle/kaggle.json\")) and os.path.exists(\"kaggle.json\"):\n",
        "    os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
        "    os.rename(\"kaggle.json\", os.path.expanduser(\"~/.kaggle/kaggle.json\"))\n",
        "    os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)"
      ],
      "metadata": {
        "id": "UFtGDlG69IVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Download dataset from Kaggle\n",
        "print(\"=== Downloading dataset from Kaggle ===\")\n",
        "os.system(\"kaggle datasets download -d parisrohan/credit-score-classification\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj_BtlRY9KhW",
        "outputId": "843c1120-82b4-456c-d47f-39c40391b69b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Downloading dataset from Kaggle ===\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Unzip the downloaded file\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_name = \"credit-score-classification.zip\"\n",
        "if os.path.exists(zip_file_name):\n",
        "    with zipfile.ZipFile(zip_file_name, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"credit_data\")\n",
        "    print(f\"Successfully unzipped {zip_file_name} to credit_data/\")\n",
        "\n",
        "    # Step 4: Load the train.csv file\n",
        "    # Assuming 'train.csv' is inside the unzipped folder 'credit_data'\n",
        "    train_csv_path = \"credit_data/train.csv\"\n",
        "    if os.path.exists(train_csv_path):\n",
        "        df = pd.read_csv(train_csv_path)\n",
        "        print(\"Dataset loaded from Kaggle successfully!\")\n",
        "    else:\n",
        "        print(f\"Error: train.csv not found in {train_csv_path}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Error: {zip_file_name} not found. Please ensure the dataset was downloaded correctly in the previous step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQqftTnq9PBj",
        "outputId": "811f761d-f5c3-49b2-e6cb-0c83bf66dc5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully unzipped credit-score-classification.zip to credit_data/\n",
            "Dataset loaded from Kaggle successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-29-3166859202.py:15: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(train_csv_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Creating Pandas DataFrame\n",
        "\n",
        "In this step, I loaded the `train.csv` file from the Kaggle dataset \"Credit Score Classification\" using the Kaggle API. I used the Pandas library to read the CSV into a DataFrame, which allows for easy manipulation and analysis of the data. I then displayed the shape of the dataset, column names, and the first few rows to get an overview of the data.\n"
      ],
      "metadata": {
        "id": "zALzzQvZA1KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) Create one Pandas data frame for this data set\n",
        "print(\"=== Task 1: Credit Score Classification Dataset ===\")\n",
        "print(\"\\n1. Creating Pandas DataFrame\")\n",
        "\n",
        "# Load the dataset\n",
        "# Note: Replace 'credit_score_data.csv' with your actual file path\n",
        "df = pd.read_csv('credit_data/train.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Column names: {list(df.columns)}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpHi88QJ9Rfl",
        "outputId": "325df443-0cbb-4d3c-e6ae-a8261bda43e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Task 1: Credit Score Classification Dataset ===\n",
            "\n",
            "1. Creating Pandas DataFrame\n",
            "Dataset shape: (100000, 28)\n",
            "Column names: ['ID', 'Customer_ID', 'Month', 'Name', 'Age', 'SSN', 'Occupation', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Type_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Credit_Mix', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age', 'Payment_of_Min_Amount', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Payment_Behaviour', 'Monthly_Balance', 'Credit_Score']\n",
            "\n",
            "First 5 rows:\n",
            "       ID Customer_ID     Month           Name   Age          SSN Occupation  \\\n",
            "0  0x1602   CUS_0xd40   January  Aaron Maashoh    23  821-00-0265  Scientist   \n",
            "1  0x1603   CUS_0xd40  February  Aaron Maashoh    23  821-00-0265  Scientist   \n",
            "2  0x1604   CUS_0xd40     March  Aaron Maashoh  -500  821-00-0265  Scientist   \n",
            "3  0x1605   CUS_0xd40     April  Aaron Maashoh    23  821-00-0265  Scientist   \n",
            "4  0x1606   CUS_0xd40       May  Aaron Maashoh    23  821-00-0265  Scientist   \n",
            "\n",
            "  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  Credit_Mix  \\\n",
            "0      19114.12            1824.843333                  3  ...           _   \n",
            "1      19114.12                    NaN                  3  ...        Good   \n",
            "2      19114.12                    NaN                  3  ...        Good   \n",
            "3      19114.12                    NaN                  3  ...        Good   \n",
            "4      19114.12            1824.843333                  3  ...        Good   \n",
            "\n",
            "   Outstanding_Debt Credit_Utilization_Ratio     Credit_History_Age  \\\n",
            "0            809.98                26.822620  22 Years and 1 Months   \n",
            "1            809.98                31.944960                    NaN   \n",
            "2            809.98                28.609352  22 Years and 3 Months   \n",
            "3            809.98                31.377862  22 Years and 4 Months   \n",
            "4            809.98                24.797347  22 Years and 5 Months   \n",
            "\n",
            "   Payment_of_Min_Amount Total_EMI_per_month Amount_invested_monthly  \\\n",
            "0                     No           49.574949       80.41529543900253   \n",
            "1                     No           49.574949      118.28022162236736   \n",
            "2                     No           49.574949         81.699521264648   \n",
            "3                     No           49.574949       199.4580743910713   \n",
            "4                     No           49.574949      41.420153086217326   \n",
            "\n",
            "                  Payment_Behaviour     Monthly_Balance Credit_Score  \n",
            "0   High_spent_Small_value_payments  312.49408867943663         Good  \n",
            "1    Low_spent_Large_value_payments  284.62916249607184         Good  \n",
            "2   Low_spent_Medium_value_payments   331.2098628537912         Good  \n",
            "3    Low_spent_Small_value_payments  223.45130972736786         Good  \n",
            "4  High_spent_Medium_value_payments  341.48923103222177         Good  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3257610822.py:7: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('credit_data/train.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Identifying Missing Values and Cleaning One Attribute\n",
        "\n",
        "I checked for missing values in all columns using `isnull().sum()`. If any missing values are found, I selected one column with missing data and proposed a cleaning method based on the column's data type:\n",
        "\n",
        "- If the column is **numerical**, I applied **mean imputation**, replacing missing values with the mean of the column.\n",
        "- If the column is **categorical**, I applied **mode imputation**, replacing missing values with the most frequent value.\n",
        "\n",
        "This ensures that no information is lost by dropping rows and helps retain the dataset's structure for future analysis.\n"
      ],
      "metadata": {
        "id": "X5nt6UPZA5p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) Identify the attributes with missing values\n",
        "print(\"\\n2. Identifying Missing Values\")\n",
        "print(\"Missing values per column:\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "# Show columns with missing values\n",
        "columns_with_missing = missing_values[missing_values > 0]\n",
        "print(f\"\\nColumns with missing values: {len(columns_with_missing)}\")\n",
        "print(columns_with_missing)\n",
        "\n",
        "# Select one attribute with missing values and propose cleaning method\n",
        "if len(columns_with_missing) > 0:\n",
        "    # Select the first column with missing values\n",
        "    selected_column = columns_with_missing.index[0]\n",
        "    print(f\"\\nSelected column for cleaning: {selected_column}\")\n",
        "    print(f\"Missing values in {selected_column}: {columns_with_missing[selected_column]}\")\n",
        "\n",
        "    # Check if it's numerical or categorical\n",
        "    if df[selected_column].dtype in ['int64', 'float64']:\n",
        "        # For numerical data, use mean imputation\n",
        "        mean_value = df[selected_column].mean()\n",
        "        df[f'{selected_column}_cleaned'] = df[selected_column].fillna(mean_value)\n",
        "        print(f\"Cleaning method: Mean imputation (value: {mean_value:.2f})\")\n",
        "    else:\n",
        "        # For categorical data, use mode imputation\n",
        "        mode_value = df[selected_column].mode()[0]\n",
        "        df[f'{selected_column}_cleaned'] = df[selected_column].fillna(mode_value)\n",
        "        print(f\"Cleaning method: Mode imputation (value: {mode_value})\")\n",
        "\n",
        "    # Verify cleaning\n",
        "    print(f\"Missing values after cleaning: {df[f'{selected_column}_cleaned'].isnull().sum()}\")\n",
        "else:\n",
        "    print(\"No missing values found in the dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqQsoTgx9dIe",
        "outputId": "3194eed0-ba15-4d0d-e595-afda3a81a319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. Identifying Missing Values\n",
            "Missing values per column:\n",
            "ID                              0\n",
            "Customer_ID                     0\n",
            "Month                           0\n",
            "Name                         9985\n",
            "Age                             0\n",
            "SSN                             0\n",
            "Occupation                      0\n",
            "Annual_Income                   0\n",
            "Monthly_Inhand_Salary       15002\n",
            "Num_Bank_Accounts               0\n",
            "Num_Credit_Card                 0\n",
            "Interest_Rate                   0\n",
            "Num_of_Loan                     0\n",
            "Type_of_Loan                11408\n",
            "Delay_from_due_date             0\n",
            "Num_of_Delayed_Payment       7002\n",
            "Changed_Credit_Limit            0\n",
            "Num_Credit_Inquiries         1965\n",
            "Credit_Mix                      0\n",
            "Outstanding_Debt                0\n",
            "Credit_Utilization_Ratio        0\n",
            "Credit_History_Age           9030\n",
            "Payment_of_Min_Amount           0\n",
            "Total_EMI_per_month             0\n",
            "Amount_invested_monthly      4479\n",
            "Payment_Behaviour               0\n",
            "Monthly_Balance              1200\n",
            "Credit_Score                    0\n",
            "dtype: int64\n",
            "\n",
            "Columns with missing values: 8\n",
            "Name                        9985\n",
            "Monthly_Inhand_Salary      15002\n",
            "Type_of_Loan               11408\n",
            "Num_of_Delayed_Payment      7002\n",
            "Num_Credit_Inquiries        1965\n",
            "Credit_History_Age          9030\n",
            "Amount_invested_monthly     4479\n",
            "Monthly_Balance             1200\n",
            "dtype: int64\n",
            "\n",
            "Selected column for cleaning: Name\n",
            "Missing values in Name: 9985\n",
            "Cleaning method: Mode imputation (value: Langep)\n",
            "Missing values after cleaning: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Z-score Normalization of \"Amount_invested_monthly\"\n",
        "\n",
        "Z-score normalization transforms the \"Amount_invested_monthly\" column so that its values have a **mean of 0** and a **standard deviation of 1**. This is done using the formula:\n",
        "\n",
        "\\[\n",
        "Z = \\frac{X - \\mu}{\\sigma}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( X \\) is the original value\n",
        "- \\( \\mu \\) is the mean\n",
        "- \\( \\sigma \\) is the standard deviation\n",
        "\n",
        "This transformation is important when comparing features with different scales or for use in algorithms that are sensitive to feature magnitude.\n"
      ],
      "metadata": {
        "id": "VhMQ8fymBAZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) Perform z-score normalization on \"Amount_invested_monthly\"\n",
        "print(\"\\n3. Z-score Normalization of Amount_invested_monthly\")\n",
        "\n",
        "if 'Amount_invested_monthly' in df.columns:\n",
        "    # Convert the column to numeric, coercing errors\n",
        "    df['Amount_invested_monthly'] = pd.to_numeric(df['Amount_invested_monthly'], errors='coerce')\n",
        "\n",
        "    # Calculate mean and standard deviation, ignoring NaN values\n",
        "    mean_amount = df['Amount_invested_monthly'].mean()\n",
        "    std_amount = df['Amount_invested_monthly'].std()\n",
        "\n",
        "    print(f\"Original mean: {mean_amount:.6f}\")\n",
        "    print(f\"Original standard deviation: {std_amount:.6f}\")\n",
        "\n",
        "    # Perform z-score normalization, handling potential NaN values\n",
        "    df['Amount_invested_monthly_zscore'] = (df['Amount_invested_monthly'] - mean_amount) / std_amount\n",
        "\n",
        "    # Calculate mean and variance of normalized values, ignoring NaN values\n",
        "    normalized_mean = df['Amount_invested_monthly_zscore'].mean()\n",
        "    normalized_variance = df['Amount_invested_monthly_zscore'].var()\n",
        "\n",
        "    print(f\"Normalized mean: {normalized_mean:.10f}\")\n",
        "    print(f\"Normalized variance: {normalized_variance:.10f}\")\n",
        "\n",
        "    print(\"\\nFirst 10 normalized values:\")\n",
        "    print(df['Amount_invested_monthly_zscore'].head(10))\n",
        "else:\n",
        "    print(\"Column 'Amount_invested_monthly' not found in dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azVqrNat9itb",
        "outputId": "a05ddfa1-9c9c-45f8-bb81-2a933c72e0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Z-score Normalization of Amount_invested_monthly\n",
            "Original mean: 195.539456\n",
            "Original standard deviation: 199.564527\n",
            "Normalized mean: 0.0000000000\n",
            "Normalized variance: 1.0000000000\n",
            "\n",
            "First 10 normalized values:\n",
            "0   -0.576877\n",
            "1   -0.387139\n",
            "2   -0.570442\n",
            "3    0.019636\n",
            "4   -0.772278\n",
            "5   -0.666999\n",
            "6   -0.086165\n",
            "7   -0.855634\n",
            "8   -0.457234\n",
            "9   -0.777434\n",
            "Name: Amount_invested_monthly_zscore, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Creating Four Equal-Frequency Bins for \"Amount_invested_monthly\"\n",
        "\n",
        "I used the `pd.qcut()` function to divide the \"Amount_invested_monthly\" column into four bins with approximately equal numbers of records in each bin. This is known as **equal-frequency binning** or **quantile binning**.\n",
        "\n",
        "The bin ranges are automatically determined based on the quartiles of the data, and each record is assigned to one of the bins (Bin1 through Bin4). This method helps in categorizing continuous variables into discrete groups for analysis or visualization.\n"
      ],
      "metadata": {
        "id": "4iu-WUVOBPWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) Create four bins for \"Amount_invested_monthly\" with equivalent numbers of records\n",
        "print(\"\\n4. Creating Four Equal-Frequency Bins\")\n",
        "\n",
        "if 'Amount_invested_monthly' in df.columns:\n",
        "    # Use pd.qcut for equal-frequency binning\n",
        "    df['Amount_invested_monthly_bins'] = pd.qcut(df['Amount_invested_monthly'],\n",
        "                                                q=4,\n",
        "                                                labels=['Bin1', 'Bin2', 'Bin3', 'Bin4'])\n",
        "\n",
        "    # Check the distribution of bins\n",
        "    bin_counts = df['Amount_invested_monthly_bins'].value_counts().sort_index()\n",
        "    print(\"Bin distribution:\")\n",
        "    print(bin_counts)\n",
        "\n",
        "    # Show bin ranges\n",
        "    print(\"\\nBin ranges:\")\n",
        "    bin_ranges = pd.qcut(df['Amount_invested_monthly'], q=4, retbins=True)[1]\n",
        "    for i, (start, end) in enumerate(zip(bin_ranges[:-1], bin_ranges[1:])):\n",
        "        print(f\"Bin{i+1}: [{start:.2f}, {end:.2f}]\")\n",
        "else:\n",
        "    print(\"Column 'Amount_invested_monthly' not found in dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15gDK4we9nGq",
        "outputId": "503225a9-4cd8-4313-a34e-cde8140623be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. Creating Four Equal-Frequency Bins\n",
            "Bin distribution:\n",
            "Amount_invested_monthly_bins\n",
            "Bin1    22804\n",
            "Bin2    22804\n",
            "Bin3    22804\n",
            "Bin4    22804\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Bin ranges:\n",
            "Bin1: [0.00, 72.24]\n",
            "Bin2: [72.24, 128.95]\n",
            "Bin3: [128.95, 236.82]\n",
            "Bin4: [236.82, 1977.33]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: One-Hot Encoding of \"Credit_Mix\"\n",
        "\n",
        "One-hot encoding is a method to convert categorical data into a numerical format that can be used in analysis or modeling. For the \"Credit_Mix\" column, I applied one-hot encoding using `pd.get_dummies()`.\n",
        "\n",
        "Each unique value in \"Credit_Mix\" is converted into a separate binary column:\n",
        "- If the original value is present in a row, the column has a value of 1.\n",
        "- Otherwise, it has a value of 0.\n",
        "\n",
        "This avoids introducing any ordinal relationship between categories and ensures that models (in future work) interpret each category independently.\n"
      ],
      "metadata": {
        "id": "yUHOnkEqBRIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (5) Apply one-hot-encoding to \"Credit_Mix\"\n",
        "print(\"\\n5. One-Hot Encoding of Credit_Mix\")\n",
        "\n",
        "if 'Credit_Mix' in df.columns:\n",
        "    # Check unique values\n",
        "    print(f\"Unique values in Credit_Mix: {df['Credit_Mix'].unique()}\")\n",
        "\n",
        "    # Apply one-hot encoding\n",
        "    credit_mix_encoded = pd.get_dummies(df['Credit_Mix'], prefix='Credit_Mix')\n",
        "\n",
        "    # Append to dataframe\n",
        "    df = pd.concat([df, credit_mix_encoded], axis=1)\n",
        "\n",
        "    print(f\"One-hot encoded columns: {list(credit_mix_encoded.columns)}\")\n",
        "    print(\"\\nFirst 5 rows of encoded data:\")\n",
        "    print(credit_mix_encoded.head())\n",
        "else:\n",
        "    print(\"Column 'Credit_Mix' not found in dataset\")\n",
        "\n",
        "# Final dataframe summary\n",
        "print(\"\\n=== Final DataFrame Summary ===\")\n",
        "print(f\"Final shape: {df.shape}\")\n",
        "print(f\"Final columns: {list(df.columns)}\")\n",
        "\n",
        "# Display first few rows of the final dataframe\n",
        "print(\"\\nFirst 3 rows of final dataframe:\")\n",
        "print(df.head(3))\n",
        "\n",
        "# Check for any remaining missing values\n",
        "print(f\"\\nTotal missing values in final dataframe: {df.isnull().sum().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_5mdKGy9q5i",
        "outputId": "7ad3d93c-b141-44e0-cc6c-0b91b2a6643a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. One-Hot Encoding of Credit_Mix\n",
            "Unique values in Credit_Mix: ['_' 'Good' 'Standard' 'Bad']\n",
            "One-hot encoded columns: ['Credit_Mix_Bad', 'Credit_Mix_Good', 'Credit_Mix_Standard', 'Credit_Mix__']\n",
            "\n",
            "First 5 rows of encoded data:\n",
            "   Credit_Mix_Bad  Credit_Mix_Good  Credit_Mix_Standard  Credit_Mix__\n",
            "0           False            False                False          True\n",
            "1           False             True                False         False\n",
            "2           False             True                False         False\n",
            "3           False             True                False         False\n",
            "4           False             True                False         False\n",
            "\n",
            "=== Final DataFrame Summary ===\n",
            "Final shape: (100000, 35)\n",
            "Final columns: ['ID', 'Customer_ID', 'Month', 'Name', 'Age', 'SSN', 'Occupation', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Type_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Credit_Mix', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age', 'Payment_of_Min_Amount', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Payment_Behaviour', 'Monthly_Balance', 'Credit_Score', 'Name_cleaned', 'Amount_invested_monthly_zscore', 'Amount_invested_monthly_bins', 'Credit_Mix_Bad', 'Credit_Mix_Good', 'Credit_Mix_Standard', 'Credit_Mix__']\n",
            "\n",
            "First 3 rows of final dataframe:\n",
            "       ID Customer_ID     Month           Name   Age          SSN Occupation  \\\n",
            "0  0x1602   CUS_0xd40   January  Aaron Maashoh    23  821-00-0265  Scientist   \n",
            "1  0x1603   CUS_0xd40  February  Aaron Maashoh    23  821-00-0265  Scientist   \n",
            "2  0x1604   CUS_0xd40     March  Aaron Maashoh  -500  821-00-0265  Scientist   \n",
            "\n",
            "  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  \\\n",
            "0      19114.12            1824.843333                  3  ...   \n",
            "1      19114.12                    NaN                  3  ...   \n",
            "2      19114.12                    NaN                  3  ...   \n",
            "\n",
            "                 Payment_Behaviour     Monthly_Balance Credit_Score  \\\n",
            "0  High_spent_Small_value_payments  312.49408867943663         Good   \n",
            "1   Low_spent_Large_value_payments  284.62916249607184         Good   \n",
            "2  Low_spent_Medium_value_payments   331.2098628537912         Good   \n",
            "\n",
            "    Name_cleaned  Amount_invested_monthly_zscore Amount_invested_monthly_bins  \\\n",
            "0  Aaron Maashoh                       -0.576877                         Bin2   \n",
            "1  Aaron Maashoh                       -0.387139                         Bin2   \n",
            "2  Aaron Maashoh                       -0.570442                         Bin2   \n",
            "\n",
            "  Credit_Mix_Bad  Credit_Mix_Good Credit_Mix_Standard Credit_Mix__  \n",
            "0          False            False               False         True  \n",
            "1          False             True               False        False  \n",
            "2          False             True               False        False  \n",
            "\n",
            "[3 rows x 35 columns]\n",
            "\n",
            "Total missing values in final dataframe: 81944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END OF ASSIGNMENT 1 TASK 1"
      ],
      "metadata": {
        "id": "kGyPZxvTBT_f"
      }
    }
  ]
}
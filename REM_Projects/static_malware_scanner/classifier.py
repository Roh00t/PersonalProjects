import yaml
import joblib
import numpy as np

class MalwareClassifier:
    def __init__(self, indicators_file="signatures.yaml", model_path="malware_model.pkl"):
        with open(indicators_file, "r") as f:
            self.signatures = yaml.safe_load(f)
        
        # Load pre-trained ML model
        try:
            self.model = joblib.load(model_path)
        except FileNotFoundError:
            self.model = None
            print("[WARNING] No trained ML model found. Using rule-based classification.")

    def check_imports(self, imports):
        """Checks if suspicious imports exist in the file."""
        malicious_imports = []
        for dll, funcs in imports.items():
            for func in funcs:
                if func in self.signatures["suspicious_imports"]:
                    malicious_imports.append(func)
        return malicious_imports

    def check_strings(self, strings):
        """Checks if any suspicious strings exist in the binary."""
        return [s for s in strings if any(sig in s for sig in self.signatures["suspicious_strings"])]

    def check_entropy(self, entropy_data):
        """Identifies sections with high entropy (possible packed malware)."""
        high_entropy_sections = {sec: ent for sec, ent in entropy_data.items() if ent > 7.0}
        return high_entropy_sections

    def extract_features(self, scan_results):
        """Converts scan results into a feature vector for ML classification."""
        num_suspicious_imports = len(self.check_imports(scan_results["Imports"]))
        num_suspicious_strings = len(self.check_strings(scan_results["Strings"]))
        high_entropy_sections = len(self.check_entropy(scan_results["Section Entropy"]))
        return np.array([num_suspicious_imports, num_suspicious_strings, high_entropy_sections]).reshape(1, -1)

    def classify(self, scan_results):
        """Evaluates scan results using rule-based and ML classification."""
        if not scan_results:
            return "Error: No scan results available."

        findings = {
            "suspicious_imports": self.check_imports(scan_results["Imports"]),
            "suspicious_strings": self.check_strings(scan_results["Strings"]),
            "high_entropy_sections": self.check_entropy(scan_results["Section Entropy"]),
        }

        # Assign risk scores (higher for imports, moderate for strings, entropy alerts)
        risk_score = (len(findings["suspicious_imports"]) * 2) + len(findings["suspicious_strings"]) + (len(findings["high_entropy_sections"]) * 2)

        # ML-based classification (if model exists)
        if self.model:
            ml_prediction = self.model.predict(self.extract_features(scan_results))[0]
            return {"Findings": findings, "Risk Score": risk_score, "ML Prediction": ml_prediction}
        
        return {"Findings": findings, "Risk Score": risk_score}